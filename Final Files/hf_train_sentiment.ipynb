{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love going happy hour dinner great patio fans ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love brewpub variety dishes nachos pizza sandw...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brother came visit wanted pick six pack good b...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bit weary trying shellfish company wharf often...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>could give zero would order plain hamburger re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0  love going happy hour dinner great patio fans ...       3\n",
       "1  love brewpub variety dishes nachos pizza sandw...       3\n",
       "2  brother came visit wanted pick six pack good b...       4\n",
       "3  bit weary trying shellfish company wharf often...       4\n",
       "4  could give zero would order plain hamburger re...       0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import pipeline\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load the preprocessed dataset into a Pandas DataFrame\n",
    "df_preproc = pd.read_parquet('sentiment_data_preprocessed.parquet')\n",
    "# df.rename(columns={'text_cleaned': 'text'}, inplace=True)\n",
    "\n",
    "df_preproc['labels'] = df_preproc['labels'].apply(lambda n: n-1)\n",
    "df_preproc = df_preproc.dropna()\n",
    "# df = df.sample(frac=.1, random_state=42)\n",
    "\n",
    "df_preproc.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# yelp_ds = load_dataset('csv', data_files= 'sentiment_data_preprocessed.csv')\n",
    "# yelp_ds = yelp_ds['train'].train_test_split(test_size=0.2, seed=42)\n",
    "# yelp_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sentiment = df[['text_cleaned', 'stars']]\n",
    "# df_sentiment.rename(columns={'text_cleaned': 'text', 'stars':'labels'}, inplace=True)\n",
    "# df_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'labels'],\n",
       "    num_rows: 415052\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.remove_columns([\"__index_level_0__\"])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = dataset.train_test_split(test_size=0.4, seed=42)\n",
    "test_valid = dataset.train_test_split(test_size=0.5, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 249031\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 207526\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 207526\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    'train': train_test['train'],\n",
    "    'validation': test_valid['train'],\n",
    "    'test' : test_valid['test'],\n",
    "})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# dataset = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# # Split the dataset into training, validation, and test sets\n",
    "# X_train, X_test, y_train, y_test = \n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.5, random_state=42)\n",
    "\n",
    "# X_train, X_val, y_train, y_val = X_train.reset_index(drop=True), X_val.reset_index(drop=True), y_train.reset_index(drop=True), y_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'coffee shop literally want go everyday staff super chill signature drinks unique',\n",
       " 'labels': 4}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'labels': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = dataset['train'].features\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.119017\n",
       "1    0.078609\n",
       "2    0.106774\n",
       "3    0.228233\n",
       "4    0.467368\n",
       "Name: labels, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "df['labels'].value_counts(normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coffee shop literally want go everyday staff s...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>place new owners fantastic flavored mini donut...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow pretty good food worth wait calamari fresh...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great small italian restaurant gnocchi ai game...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>come 10 torr regularly right around corner off...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249026</th>\n",
       "      <td>stopped new place monday evening maybe best ni...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249027</th>\n",
       "      <td>excellent pho spring rolls nice pho broth real...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249028</th>\n",
       "      <td>terrible service incorrect orders late deliver...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249029</th>\n",
       "      <td>havent bfast spot since kid far best breakfast...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249030</th>\n",
       "      <td>amazing desserts milkshakes looked like art go...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249031 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  labels\n",
       "0       coffee shop literally want go everyday staff s...       4\n",
       "1       place new owners fantastic flavored mini donut...       4\n",
       "2       wow pretty good food worth wait calamari fresh...       3\n",
       "3       great small italian restaurant gnocchi ai game...       4\n",
       "4       come 10 torr regularly right around corner off...       3\n",
       "...                                                   ...     ...\n",
       "249026  stopped new place monday evening maybe best ni...       1\n",
       "249027  excellent pho spring rolls nice pho broth real...       4\n",
       "249028  terrible service incorrect orders late deliver...       0\n",
       "249029  havent bfast spot since kid far best breakfast...       4\n",
       "249030  amazing desserts milkshakes looked like art go...       4\n",
       "\n",
       "[249031 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_ckpt = 'microsoft/MiniLM-L12-H384-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 4157, 4497, 6719, 2215, 2175, 10126, 3095, 3565, 10720, 8085, 8974, 4310, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(dataset['train']['text'][:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c7e8026b2ae4076bc6037870a36c2cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/249031 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0831854c88a4645b6b256bda82f78ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/207526 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68deff19468c4c09b5fff76f107fb7a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/207526 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 249031\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 207526\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 207526\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.map(tokenize_text, batched=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999952, 0.99999968, 0.99999957, 0.99999908, 0.99999812])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = (1-(df['labels'].value_counts(normalize=True).sort_index() / len(df))).values\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "class_weights = torch.from_numpy(class_weights).float().to('cuda')\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from transformers import Trainer\n",
    "\n",
    "class WeightedLossTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "\n",
    "        labels = inputs.get('labels')\n",
    "\n",
    "        loss_func = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "        loss=loss_func(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    return {'f1':f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "logging_steps = len(dataset['train']) // batch_size\n",
    "output_dir = 'minilm-finetuned-yelp'\n",
    "training_args = TrainingArguments(output_dir=output_dir,\n",
    "                                  num_train_epochs=15,\n",
    "                                  learning_rate=5e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy='epoch',\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  fp16=False,\n",
    "                                  push_to_hub=True,\n",
    "                                  save_steps=10000\n",
    "                                  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/kaitou/minilm-finetuned-yelp into local empty directory.\n"
     ]
    }
   ],
   "source": [
    "trainer= WeightedLossTrainer(model=model,\n",
    "                             args=training_args,\n",
    "                             compute_metrics=compute_metrics,\n",
    "                             train_dataset=dataset['train'],\n",
    "                             eval_dataset=dataset['validation'],\n",
    "                             tokenizer=tokenizer,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid.\n",
      "Your token has been saved to C:\\Users\\}{\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "# notebook_login()\n",
    "!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\}{\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 249031\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 233475\n",
      "  Number of trainable parameters = 33361925\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42affbcb17d24015b305844814c28fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/233475 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Saving model checkpoint to minilm-finetuned-yelp\\checkpoint-10000\n",
      "Configuration saved in minilm-finetuned-yelp\\checkpoint-10000\\config.json\n",
      "Model weights saved in minilm-finetuned-yelp\\checkpoint-10000\\pytorch_model.bin\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\checkpoint-10000\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\checkpoint-10000\\special_tokens_map.json\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 207526\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.858, 'learning_rate': 4.666688082235786e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8ac1fa47f24436b75563d85119068f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12971 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7553852200508118, 'eval_f1': 0.6473943599058882, 'eval_runtime': 427.6047, 'eval_samples_per_second': 485.322, 'eval_steps_per_second': 30.334, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to minilm-finetuned-yelp\\checkpoint-20000\n",
      "Configuration saved in minilm-finetuned-yelp\\checkpoint-20000\\config.json\n",
      "Model weights saved in minilm-finetuned-yelp\\checkpoint-20000\\pytorch_model.bin\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\checkpoint-20000\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\checkpoint-20000\\special_tokens_map.json\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\special_tokens_map.json\n",
      "Several commits (2) will be pushed upstream.\n",
      "Saving model checkpoint to minilm-finetuned-yelp\\checkpoint-30000\n",
      "Configuration saved in minilm-finetuned-yelp\\checkpoint-30000\\config.json\n",
      "Model weights saved in minilm-finetuned-yelp\\checkpoint-30000\\pytorch_model.bin\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\checkpoint-30000\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\checkpoint-30000\\special_tokens_map.json\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\special_tokens_map.json\n",
      "Several commits (3) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7528, 'learning_rate': 4.333376164471571e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 207526\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43d1162b1e24af6a77ad5cb89dc743d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12971 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6906121969223022, 'eval_f1': 0.6960419654441062, 'eval_runtime': 426.8115, 'eval_samples_per_second': 486.224, 'eval_steps_per_second': 30.39, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to minilm-finetuned-yelp\\checkpoint-40000\n",
      "Configuration saved in minilm-finetuned-yelp\\checkpoint-40000\\config.json\n",
      "Model weights saved in minilm-finetuned-yelp\\checkpoint-40000\\pytorch_model.bin\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\checkpoint-40000\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\checkpoint-40000\\special_tokens_map.json\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\special_tokens_map.json\n",
      "Several commits (4) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7071, 'learning_rate': 4.0000642467073563e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 207526\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1f86bb9b7048c28edbf545da557ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12971 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6578182578086853, 'eval_f1': 0.7272650752141089, 'eval_runtime': 427.0929, 'eval_samples_per_second': 485.904, 'eval_steps_per_second': 30.37, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to minilm-finetuned-yelp\\checkpoint-50000\n",
      "Configuration saved in minilm-finetuned-yelp\\checkpoint-50000\\config.json\n",
      "Model weights saved in minilm-finetuned-yelp\\checkpoint-50000\\pytorch_model.bin\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\checkpoint-50000\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\checkpoint-50000\\special_tokens_map.json\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\special_tokens_map.json\n",
      "Several commits (5) will be pushed upstream.\n",
      "Saving model checkpoint to minilm-finetuned-yelp\\checkpoint-60000\n",
      "Configuration saved in minilm-finetuned-yelp\\checkpoint-60000\\config.json\n",
      "Model weights saved in minilm-finetuned-yelp\\checkpoint-60000\\pytorch_model.bin\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\checkpoint-60000\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\checkpoint-60000\\special_tokens_map.json\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\special_tokens_map.json\n",
      "Several commits (6) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6654, 'learning_rate': 3.666752328943141e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 207526\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa9ce2fb75864c2ca5db8a8e333460dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12971 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5850256085395813, 'eval_f1': 0.7584655738726847, 'eval_runtime': 431.8394, 'eval_samples_per_second': 480.563, 'eval_steps_per_second': 30.037, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to minilm-finetuned-yelp\\checkpoint-70000\n",
      "Configuration saved in minilm-finetuned-yelp\\checkpoint-70000\\config.json\n",
      "Model weights saved in minilm-finetuned-yelp\\checkpoint-70000\\pytorch_model.bin\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\checkpoint-70000\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\checkpoint-70000\\special_tokens_map.json\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\special_tokens_map.json\n",
      "Several commits (7) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6229, 'learning_rate': 3.3334404111789275e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 207526\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e5e3accf284747a4cdc9a22737257e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12971 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5385793447494507, 'eval_f1': 0.7825056863901135, 'eval_runtime': 431.4143, 'eval_samples_per_second': 481.036, 'eval_steps_per_second': 30.066, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to minilm-finetuned-yelp\\checkpoint-80000\n",
      "Configuration saved in minilm-finetuned-yelp\\checkpoint-80000\\config.json\n",
      "Model weights saved in minilm-finetuned-yelp\\checkpoint-80000\\pytorch_model.bin\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\checkpoint-80000\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\checkpoint-80000\\special_tokens_map.json\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\special_tokens_map.json\n",
      "Several commits (8) will be pushed upstream.\n",
      "Saving model checkpoint to minilm-finetuned-yelp\\checkpoint-90000\n",
      "Configuration saved in minilm-finetuned-yelp\\checkpoint-90000\\config.json\n",
      "Model weights saved in minilm-finetuned-yelp\\checkpoint-90000\\pytorch_model.bin\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\checkpoint-90000\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\checkpoint-90000\\special_tokens_map.json\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\special_tokens_map.json\n",
      "Several commits (9) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5796, 'learning_rate': 3.0001284934147128e-05, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 207526\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea2b0b6e26746b8a56a0e35648a38a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12971 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4821244776248932, 'eval_f1': 0.8187590772661449, 'eval_runtime': 431.8405, 'eval_samples_per_second': 480.562, 'eval_steps_per_second': 30.037, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to minilm-finetuned-yelp\\checkpoint-100000\n",
      "Configuration saved in minilm-finetuned-yelp\\checkpoint-100000\\config.json\n",
      "Model weights saved in minilm-finetuned-yelp\\checkpoint-100000\\pytorch_model.bin\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\checkpoint-100000\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\checkpoint-100000\\special_tokens_map.json\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\special_tokens_map.json\n",
      "Several commits (10) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5367, 'learning_rate': 2.666816575650498e-05, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 207526\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b046585e1544488ac56fccafb72b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12971 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.42541003227233887, 'eval_f1': 0.8423243370295005, 'eval_runtime': 436.3945, 'eval_samples_per_second': 475.547, 'eval_steps_per_second': 29.723, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to minilm-finetuned-yelp\\checkpoint-110000\n",
      "Configuration saved in minilm-finetuned-yelp\\checkpoint-110000\\config.json\n",
      "Model weights saved in minilm-finetuned-yelp\\checkpoint-110000\\pytorch_model.bin\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\checkpoint-110000\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\checkpoint-110000\\special_tokens_map.json\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\special_tokens_map.json\n",
      "Several commits (11) will be pushed upstream.\n",
      "Saving model checkpoint to minilm-finetuned-yelp\\checkpoint-120000\n",
      "Configuration saved in minilm-finetuned-yelp\\checkpoint-120000\\config.json\n",
      "Model weights saved in minilm-finetuned-yelp\\checkpoint-120000\\pytorch_model.bin\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\checkpoint-120000\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\checkpoint-120000\\special_tokens_map.json\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\special_tokens_map.json\n",
      "Several commits (12) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4962, 'learning_rate': 2.3335046578862836e-05, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 207526\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "551b25a2a5834b1281d6ed73df0f0b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12971 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.37922847270965576, 'eval_f1': 0.8696387994007095, 'eval_runtime': 428.7435, 'eval_samples_per_second': 484.033, 'eval_steps_per_second': 30.254, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to minilm-finetuned-yelp\\checkpoint-130000\n",
      "Configuration saved in minilm-finetuned-yelp\\checkpoint-130000\\config.json\n",
      "Model weights saved in minilm-finetuned-yelp\\checkpoint-130000\\pytorch_model.bin\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\checkpoint-130000\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\checkpoint-130000\\special_tokens_map.json\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\special_tokens_map.json\n",
      "Several commits (13) will be pushed upstream.\n",
      "Saving model checkpoint to minilm-finetuned-yelp\\checkpoint-140000\n",
      "Configuration saved in minilm-finetuned-yelp\\checkpoint-140000\\config.json\n",
      "Model weights saved in minilm-finetuned-yelp\\checkpoint-140000\\pytorch_model.bin\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\checkpoint-140000\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\checkpoint-140000\\special_tokens_map.json\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\special_tokens_map.json\n",
      "Several commits (14) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4574, 'learning_rate': 2.000192740122069e-05, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 207526\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca9c7e1763047409237e4e413890c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12971 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.33641642332077026, 'eval_f1': 0.8843217228164648, 'eval_runtime': 428.2047, 'eval_samples_per_second': 484.642, 'eval_steps_per_second': 30.292, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to minilm-finetuned-yelp\\checkpoint-150000\n",
      "Configuration saved in minilm-finetuned-yelp\\checkpoint-150000\\config.json\n",
      "Model weights saved in minilm-finetuned-yelp\\checkpoint-150000\\pytorch_model.bin\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\checkpoint-150000\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\checkpoint-150000\\special_tokens_map.json\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\special_tokens_map.json\n",
      "Several commits (15) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4222, 'learning_rate': 1.666880822357854e-05, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 207526\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5bd2dbe3f14e9b93fcf1fbe6ea2af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12971 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28931283950805664, 'eval_f1': 0.9042034093047879, 'eval_runtime': 4346.4884, 'eval_samples_per_second': 47.746, 'eval_steps_per_second': 2.984, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to minilm-finetuned-yelp\\checkpoint-160000\n",
      "Configuration saved in minilm-finetuned-yelp\\checkpoint-160000\\config.json\n",
      "Model weights saved in minilm-finetuned-yelp\\checkpoint-160000\\pytorch_model.bin\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\checkpoint-160000\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\checkpoint-160000\\special_tokens_map.json\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\special_tokens_map.json\n",
      "Several commits (16) will be pushed upstream.\n",
      "Saving model checkpoint to minilm-finetuned-yelp\\checkpoint-170000\n",
      "Configuration saved in minilm-finetuned-yelp\\checkpoint-170000\\config.json\n",
      "Model weights saved in minilm-finetuned-yelp\\checkpoint-170000\\pytorch_model.bin\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\checkpoint-170000\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\checkpoint-170000\\special_tokens_map.json\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\special_tokens_map.json\n",
      "Several commits (17) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3903, 'learning_rate': 1.3335689045936397e-05, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 207526\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b431eb9e514e4e9c0c52fc5e50ce4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12971 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.25822898745536804, 'eval_f1': 0.9167015190778822, 'eval_runtime': 446.6116, 'eval_samples_per_second': 464.668, 'eval_steps_per_second': 29.043, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to minilm-finetuned-yelp\\checkpoint-180000\n",
      "Configuration saved in minilm-finetuned-yelp\\checkpoint-180000\\config.json\n",
      "Model weights saved in minilm-finetuned-yelp\\checkpoint-180000\\pytorch_model.bin\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\checkpoint-180000\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\checkpoint-180000\\special_tokens_map.json\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\special_tokens_map.json\n",
      "Several commits (18) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3626, 'learning_rate': 1.0002569868294252e-05, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 207526\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9bc84517734a3a97070252c904b9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12971 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22856532037258148, 'eval_f1': 0.9282644202736262, 'eval_runtime': 428.3814, 'eval_samples_per_second': 484.442, 'eval_steps_per_second': 30.279, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to minilm-finetuned-yelp\\checkpoint-190000\n",
      "Configuration saved in minilm-finetuned-yelp\\checkpoint-190000\\config.json\n",
      "Model weights saved in minilm-finetuned-yelp\\checkpoint-190000\\pytorch_model.bin\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\checkpoint-190000\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\checkpoint-190000\\special_tokens_map.json\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\special_tokens_map.json\n",
      "Several commits (19) will be pushed upstream.\n",
      "Saving model checkpoint to minilm-finetuned-yelp\\checkpoint-200000\n",
      "Configuration saved in minilm-finetuned-yelp\\checkpoint-200000\\config.json\n",
      "Model weights saved in minilm-finetuned-yelp\\checkpoint-200000\\pytorch_model.bin\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\checkpoint-200000\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\checkpoint-200000\\special_tokens_map.json\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\special_tokens_map.json\n",
      "Several commits (20) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3386, 'learning_rate': 6.669450690652104e-06, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 207526\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1660db816d36432bbff88f560920975b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12971 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20290784537792206, 'eval_f1': 0.9391609036077688, 'eval_runtime': 428.3125, 'eval_samples_per_second': 484.52, 'eval_steps_per_second': 30.284, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to minilm-finetuned-yelp\\checkpoint-210000\n",
      "Configuration saved in minilm-finetuned-yelp\\checkpoint-210000\\config.json\n",
      "Model weights saved in minilm-finetuned-yelp\\checkpoint-210000\\pytorch_model.bin\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\checkpoint-210000\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\checkpoint-210000\\special_tokens_map.json\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\special_tokens_map.json\n",
      "Several commits (21) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3213, 'learning_rate': 3.336331513009958e-06, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 207526\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99b81edb30a49e5944a6e9bb65b0377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12971 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1911805421113968, 'eval_f1': 0.9442512598340941, 'eval_runtime': 428.9762, 'eval_samples_per_second': 483.77, 'eval_steps_per_second': 30.237, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to minilm-finetuned-yelp\\checkpoint-220000\n",
      "Configuration saved in minilm-finetuned-yelp\\checkpoint-220000\\config.json\n",
      "Model weights saved in minilm-finetuned-yelp\\checkpoint-220000\\pytorch_model.bin\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\checkpoint-220000\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\checkpoint-220000\\special_tokens_map.json\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\special_tokens_map.json\n",
      "Several commits (22) will be pushed upstream.\n",
      "Saving model checkpoint to minilm-finetuned-yelp\\checkpoint-230000\n",
      "Configuration saved in minilm-finetuned-yelp\\checkpoint-230000\\config.json\n",
      "Model weights saved in minilm-finetuned-yelp\\checkpoint-230000\\pytorch_model.bin\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\checkpoint-230000\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\checkpoint-230000\\special_tokens_map.json\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\special_tokens_map.json\n",
      "Several commits (23) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3063, 'learning_rate': 3.2123353678123996e-09, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 207526\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b04b3e317744523a1f13dbfbe67f853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12971 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18377083539962769, 'eval_f1': 0.9467422575650517, 'eval_runtime': 427.8337, 'eval_samples_per_second': 485.062, 'eval_steps_per_second': 30.318, 'epoch': 15.0}\n",
      "{'train_runtime': 40029.2517, 'train_samples_per_second': 93.318, 'train_steps_per_second': 5.833, 'train_loss': 0.52113987051505, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=233475, training_loss=0.52113987051505, metrics={'train_runtime': 40029.2517, 'train_samples_per_second': 93.318, 'train_steps_per_second': 5.833, 'train_loss': 0.52113987051505, 'epoch': 15.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to minilm-finetuned-yelp\n",
      "Configuration saved in minilm-finetuned-yelp\\config.json\n",
      "Model weights saved in minilm-finetuned-yelp\\pytorch_model.bin\n",
      "tokenizer config file saved in minilm-finetuned-yelp\\tokenizer_config.json\n",
      "Special tokens file saved in minilm-finetuned-yelp\\special_tokens_map.json\n",
      "Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Text Classification', 'type': 'text-classification'}, 'metrics': [{'name': 'F1', 'type': 'f1', 'value': 0.9467422575650517}]}\n"
     ]
    }
   ],
   "source": [
    "# model.save_pretrained(output_dir)\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file minilm-finetuned-yelp\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"minilm-finetuned-yelp\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 384,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file minilm-finetuned-yelp\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"minilm-finetuned-yelp\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 384,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file minilm-finetuned-yelp\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at minilm-finetuned-yelp.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "my_model = 'minilm-finetuned-yelp'\n",
    "pipe = pipeline('sentiment-analysis', my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = dataset['test'].to_pandas()[['text','labels']]\n",
    "\n",
    "test_result = df_test['text'].apply(lambda text: pipe(text[:512]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(415052,\n",
       " 0         [{'label': 'LABEL_3', 'score': 0.9796379208564...\n",
       " 1         [{'label': 'LABEL_3', 'score': 0.5744537711143...\n",
       " 2         [{'label': 'LABEL_4', 'score': 0.9511278271675...\n",
       " 3         [{'label': 'LABEL_2', 'score': 0.9871237277984...\n",
       " 4         [{'label': 'LABEL_0', 'score': 0.9835019707679...\n",
       "                                 ...                        \n",
       " 415061    [{'label': 'LABEL_3', 'score': 0.9805882573127...\n",
       " 415062    [{'label': 'LABEL_4', 'score': 0.9469411373138...\n",
       " 415063    [{'label': 'LABEL_4', 'score': 0.9731036424636...\n",
       " 415064    [{'label': 'LABEL_3', 'score': 0.9731329083442...\n",
       " 415065    [{'label': 'LABEL_0', 'score': 0.9701607227325...\n",
       " Name: text, Length: 415052, dtype: object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this = df_preproc['text'].apply(lambda text: pipe(text[:512]))\n",
    "\n",
    "len(df_preproc['text']),this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love going happy hour dinner great patio fans ...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.979638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love brewpub variety dishes nachos pizza sandw...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.574454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brother came visit wanted pick six pack good b...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.951128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bit weary trying shellfish company wharf often...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.987124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>could give zero would order plain hamburger re...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415061</th>\n",
       "      <td>first time today happened mothers day around 1...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.980588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415062</th>\n",
       "      <td>incredible amazing always come philly get fish...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.946941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415063</th>\n",
       "      <td>hesitant try la margarita thinking would super...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.973104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415064</th>\n",
       "      <td>place times lunch buffet dinner would definite...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.973133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415065</th>\n",
       "      <td>excited food saw unfortunately place closes ea...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.970161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>415052 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  stars  label  \\\n",
       "0       love going happy hour dinner great patio fans ...      3      4   \n",
       "1       love brewpub variety dishes nachos pizza sandw...      3      4   \n",
       "2       brother came visit wanted pick six pack good b...      4      5   \n",
       "3       bit weary trying shellfish company wharf often...      4      3   \n",
       "4       could give zero would order plain hamburger re...      0      1   \n",
       "...                                                   ...    ...    ...   \n",
       "415061  first time today happened mothers day around 1...      3      4   \n",
       "415062  incredible amazing always come philly get fish...      4      5   \n",
       "415063  hesitant try la margarita thinking would super...      4      5   \n",
       "415064  place times lunch buffet dinner would definite...      3      4   \n",
       "415065  excited food saw unfortunately place closes ea...      2      1   \n",
       "\n",
       "           score  \n",
       "0       0.979638  \n",
       "1       0.574454  \n",
       "2       0.951128  \n",
       "3       0.987124  \n",
       "4       0.983502  \n",
       "...          ...  \n",
       "415061  0.980588  \n",
       "415062  0.946941  \n",
       "415063  0.973104  \n",
       "415064  0.973133  \n",
       "415065  0.970161  \n",
       "\n",
       "[415052 rows x 4 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sent = pd.DataFrame(df_preproc['text'])\n",
    "df_sent['stars'], df_sent['label'], df_sent['score'] = df_preproc['labels'], this.apply(lambda result: int(result[0]['label'][-1])+1), this.apply(lambda result: result[0]['score'])\n",
    "df_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
    "# analyzer = pipeline(\"sentiment-analysis\", model=model_ckpt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372a041f15964879bf6f0e0d55d4a4b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/954 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\}{/.cache\\huggingface\\hub\\models--lewtun--minilm-finetuned-emotion\\snapshots\\2e1ecc37e5edd7eb71dec436923ad199f57825c6\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"lewtun/minilm-finetuned-emotion\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 384,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"sadness\",\n",
      "    \"1\": \"joy\",\n",
      "    \"2\": \"love\",\n",
      "    \"3\": \"anger\",\n",
      "    \"4\": \"fear\",\n",
      "    \"5\": \"surprise\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 3,\n",
      "    \"fear\": 4,\n",
      "    \"joy\": 1,\n",
      "    \"love\": 2,\n",
      "    \"sadness\": 0,\n",
      "    \"surprise\": 5\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\}{/.cache\\huggingface\\hub\\models--lewtun--minilm-finetuned-emotion\\snapshots\\2e1ecc37e5edd7eb71dec436923ad199f57825c6\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"lewtun/minilm-finetuned-emotion\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 384,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"sadness\",\n",
      "    \"1\": \"joy\",\n",
      "    \"2\": \"love\",\n",
      "    \"3\": \"anger\",\n",
      "    \"4\": \"fear\",\n",
      "    \"5\": \"surprise\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 3,\n",
      "    \"fear\": 4,\n",
      "    \"joy\": 1,\n",
      "    \"love\": 2,\n",
      "    \"sadness\": 0,\n",
      "    \"surprise\": 5\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2834970a68d84691bc26b0bc60fe1c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at C:\\Users\\}{/.cache\\huggingface\\hub\\models--lewtun--minilm-finetuned-emotion\\snapshots\\2e1ecc37e5edd7eb71dec436923ad199f57825c6\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at lewtun/minilm-finetuned-emotion.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8de06ff94948338f45aa29e5fd5aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/525 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d4279685aa437783c3014da1fbad6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2856bc05c93c47e78be4339d36942a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2472bc4bef554254ae13b56ae868915c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at C:\\Users\\}{/.cache\\huggingface\\hub\\models--lewtun--minilm-finetuned-emotion\\snapshots\\2e1ecc37e5edd7eb71dec436923ad199f57825c6\\vocab.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\}{/.cache\\huggingface\\hub\\models--lewtun--minilm-finetuned-emotion\\snapshots\\2e1ecc37e5edd7eb71dec436923ad199f57825c6\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\}{/.cache\\huggingface\\hub\\models--lewtun--minilm-finetuned-emotion\\snapshots\\2e1ecc37e5edd7eb71dec436923ad199f57825c6\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\}{/.cache\\huggingface\\hub\\models--lewtun--minilm-finetuned-emotion\\snapshots\\2e1ecc37e5edd7eb71dec436923ad199f57825c6\\tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "emotion_model = 'lewtun/minilm-finetuned-emotion'\n",
    "emo_pipe = pipeline('text-classification', emotion_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('love going happy hour dinner great patio fans beat stl heat alsovery accomodating location like veal milanese mixed greens instead pasta theyll modify menu suit taste',\n",
       " [{'label': 'joy', 'score': 0.8993651270866394}])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = df_preproc['text'][0][:512]\n",
    "ex, emo_pipe(ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12step program help manage reanimator coffee problem please share \n",
      " [{'label': 'sadness', 'score': 0.35848113894462585}]\n",
      "beautifully sweet ending sweet trip nola girls stumbled upon delicous savory lunch nearby cochon review follow sweet confections magazine st around corner art gallery strip julia st sampling cupcake chocolate mocha filling truffles raspberry creme brulee orange cupcake good mocha filling best part rasberry truffle fav love dark chocolate cloyingly sweet coffee wonderful chaser overly burnt smoky acidic usually coffee milk n sugar forgot time didnt even need seating nice cafe tables inside enough 6girl troop \n",
      " [{'label': 'love', 'score': 0.5278953909873962}]\n",
      "great place bring kids juice slice cake homemade popsicles think tea party tried everything favorites homemade doughnuts filled read bean popsicles patbingsu even good ol coffee cream sugar \n",
      " [{'label': 'love', 'score': 0.6177704930305481}]\n",
      "much care given healthy delicious food ex japanese squash rather white potatoes curry thay nice touches like welcome snack straw wrappers twisted rose sauces amazing menu many options accomodate special dietary needs easily since everything made scratch even desserts extra touch using white black sticky rice goto thai \n",
      " [{'label': 'joy', 'score': 0.9003113508224487}]\n",
      "need cinnamon roll bake house probably need two life would little less happiness light without cinnamon rolls coffee salads also excellent lovely saturday morning breakfast treat \n",
      " [{'label': 'joy', 'score': 0.7223807573318481}]\n",
      "great breakfast fare eggs provenale pretty good kinds herbs seasonings cooked inconsistently tomato side awesome omelets executed well pastries pretty impressive coffee horrendously bad without good coffee whats point breakfast still cant trust restaurants misspellings menus even misspelling another language \n",
      " [{'label': 'joy', 'score': 0.8918778300285339}]\n",
      "went monday daiquiri watch little bit nba basketball game asked young lady working would willing turn game told watching netflix guess customer service important anymore wont ever go back \n",
      " [{'label': 'joy', 'score': 0.9034568667411804}]\n",
      "quick friendly service great portion size price pancakes ordered perfect consistency \n",
      " [{'label': 'joy', 'score': 0.9008877277374268}]\n",
      "visited brewpub several times im finally ready write review really like decor oldschool brewpub lots games children beer pretty good wish would adventurous offerings still get good beer food mixed bag small pizza gooey mess mushrooms hearty toppings need thick crust stability love scotch egg offerings get pizza burger salty burgers good desserts great please get frangipane also great get ploughmans plate beer relax bit \n",
      " [{'label': 'joy', 'score': 0.8999679088592529}]\n",
      "consistent quality service love 1 deluxe props amanda excellent customer service beyond \n",
      " [{'label': 'joy', 'score': 0.8695022463798523}]\n"
     ]
    }
   ],
   "source": [
    "for i in range(50,60):\n",
    "    ex = df_preproc['text'][i][:512]\n",
    "    print (ex, '\\n', emo_pipe(ex))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           [{'label': 'joy', 'score': 0.8993651270866394}]\n",
       "1           [{'label': 'joy', 'score': 0.8529354929924011}]\n",
       "2           [{'label': 'joy', 'score': 0.9102669358253479}]\n",
       "3         [{'label': 'sadness', 'score': 0.8094623684883...\n",
       "4          [{'label': 'anger', 'score': 0.757133960723877}]\n",
       "                                ...                        \n",
       "415061      [{'label': 'joy', 'score': 0.5986286401748657}]\n",
       "415062      [{'label': 'love', 'score': 0.459367036819458}]\n",
       "415063      [{'label': 'joy', 'score': 0.5384106636047363}]\n",
       "415064      [{'label': 'joy', 'score': 0.9112372994422913}]\n",
       "415065      [{'label': 'joy', 'score': 0.7565946578979492}]\n",
       "Name: text, Length: 415052, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emo_result = df_preproc['text'].apply(lambda text: emo_pipe(text[:512]))\n",
    "emo_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love going happy hour dinner great patio fans ...</td>\n",
       "      <td>3</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.899365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love brewpub variety dishes nachos pizza sandw...</td>\n",
       "      <td>3</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.852935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brother came visit wanted pick six pack good b...</td>\n",
       "      <td>4</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.910267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bit weary trying shellfish company wharf often...</td>\n",
       "      <td>4</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.809462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>could give zero would order plain hamburger re...</td>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.757134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415061</th>\n",
       "      <td>first time today happened mothers day around 1...</td>\n",
       "      <td>3</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.598629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415062</th>\n",
       "      <td>incredible amazing always come philly get fish...</td>\n",
       "      <td>4</td>\n",
       "      <td>love</td>\n",
       "      <td>0.459367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415063</th>\n",
       "      <td>hesitant try la margarita thinking would super...</td>\n",
       "      <td>4</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.538411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415064</th>\n",
       "      <td>place times lunch buffet dinner would definite...</td>\n",
       "      <td>3</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.911237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415065</th>\n",
       "      <td>excited food saw unfortunately place closes ea...</td>\n",
       "      <td>2</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.756595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>415052 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  stars  emotion  \\\n",
       "0       love going happy hour dinner great patio fans ...      3      joy   \n",
       "1       love brewpub variety dishes nachos pizza sandw...      3      joy   \n",
       "2       brother came visit wanted pick six pack good b...      4      joy   \n",
       "3       bit weary trying shellfish company wharf often...      4  sadness   \n",
       "4       could give zero would order plain hamburger re...      0    anger   \n",
       "...                                                   ...    ...      ...   \n",
       "415061  first time today happened mothers day around 1...      3      joy   \n",
       "415062  incredible amazing always come philly get fish...      4     love   \n",
       "415063  hesitant try la margarita thinking would super...      4      joy   \n",
       "415064  place times lunch buffet dinner would definite...      3      joy   \n",
       "415065  excited food saw unfortunately place closes ea...      2      joy   \n",
       "\n",
       "           score  \n",
       "0       0.899365  \n",
       "1       0.852935  \n",
       "2       0.910267  \n",
       "3       0.809462  \n",
       "4       0.757134  \n",
       "...          ...  \n",
       "415061  0.598629  \n",
       "415062  0.459367  \n",
       "415063  0.538411  \n",
       "415064  0.911237  \n",
       "415065  0.756595  \n",
       "\n",
       "[415052 rows x 4 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emo = pd.DataFrame(df_preproc['text'])\n",
    "df_emo['stars'],df_emo['emotion'],df_emo['score'] = df_preproc['labels'], emo_result.apply(lambda result: result[0]['label']), emo_result.apply(lambda result: result[0]['score'])\n",
    "df_emo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent.to_parquet('yelp_sentiments.parquet')\n",
    "df_emo.to_parquet('yelp_emotions.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
