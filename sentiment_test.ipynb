{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a955b2d813644a69978b77c18931d39f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d492394645c6426a8dc6b0d0a82aa40b",
              "IPY_MODEL_63a73e496d0844c6adf51ee21ed3931b",
              "IPY_MODEL_236f5bd0c040407390beae7ba7bc8238"
            ],
            "layout": "IPY_MODEL_7ab1c3f31f7a4a258cfb4470b56b83b9",
            "tabbable": null,
            "tooltip": null
          }
        },
        "d492394645c6426a8dc6b0d0a82aa40b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_ff139686554340bda7d1857cb7c629a2",
            "placeholder": "​",
            "style": "IPY_MODEL_ac06e5cdc31841b78ff32de2989ff3a2",
            "tabbable": null,
            "tooltip": null,
            "value": "  0%"
          }
        },
        "63a73e496d0844c6adf51ee21ed3931b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_50996f15f627471c85fae355216ec306",
            "max": 6990280,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d8812a43f5e47d6be853415070a4c04",
            "tabbable": null,
            "tooltip": null,
            "value": 0
          }
        },
        "236f5bd0c040407390beae7ba7bc8238": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_297011ffef2947a2a273ec3d80465980",
            "placeholder": "​",
            "style": "IPY_MODEL_2255fed6210743489c711b56c22013cb",
            "tabbable": null,
            "tooltip": null,
            "value": " 0/6990280 [00:07&lt;?, ?it/s]"
          }
        },
        "7ab1c3f31f7a4a258cfb4470b56b83b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff139686554340bda7d1857cb7c629a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac06e5cdc31841b78ff32de2989ff3a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "50996f15f627471c85fae355216ec306": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d8812a43f5e47d6be853415070a4c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "297011ffef2947a2a273ec3d80465980": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2255fed6210743489c711b56c22013cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "ov8Xwpu5boa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = r'Desktop/ipynb notebooks - practice, examples, and class files/DATA606Capstone/yelp_reviews_food_categories.csv'\n",
        "# reading in merged csv as df\n",
        "yelp = pd.read_csv(path)\n",
        "yelp.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "id": "GfeatVkxflJ8",
        "outputId": "639d5745-ec6f-4ca4-deec-afc18fb132a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              business_id             name          address        city state  \\\n",
              "0  2AwhlMOMsYXJvskZKKG2GA  Tequila Sunrise  1551 N Green St  Brownsburg    IN   \n",
              "1  2AwhlMOMsYXJvskZKKG2GA  Tequila Sunrise  1551 N Green St  Brownsburg    IN   \n",
              "2  2AwhlMOMsYXJvskZKKG2GA  Tequila Sunrise  1551 N Green St  Brownsburg    IN   \n",
              "3  2AwhlMOMsYXJvskZKKG2GA  Tequila Sunrise  1551 N Green St  Brownsburg    IN   \n",
              "4  2AwhlMOMsYXJvskZKKG2GA  Tequila Sunrise  1551 N Green St  Brownsburg    IN   \n",
              "\n",
              "  postal_code   latitude  longitude  stars_x  review_count  ...  \\\n",
              "0       46112  39.867338 -86.390529      3.5         112.0  ...   \n",
              "1       46112  39.867338 -86.390529      3.5         112.0  ...   \n",
              "2       46112  39.867338 -86.390529      3.5         112.0  ...   \n",
              "3       46112  39.867338 -86.390529      3.5         112.0  ...   \n",
              "4       46112  39.867338 -86.390529      3.5         112.0  ...   \n",
              "\n",
              "                                          attributes            categories  \\\n",
              "0  {'NoiseLevel': \"u'average'\", 'BusinessParking'...  Restaurants, Mexican   \n",
              "1  {'NoiseLevel': \"u'average'\", 'BusinessParking'...  Restaurants, Mexican   \n",
              "2  {'NoiseLevel': \"u'average'\", 'BusinessParking'...  Restaurants, Mexican   \n",
              "3  {'NoiseLevel': \"u'average'\", 'BusinessParking'...  Restaurants, Mexican   \n",
              "4  {'NoiseLevel': \"u'average'\", 'BusinessParking'...  Restaurants, Mexican   \n",
              "\n",
              "                review_id                 user_id stars_y  useful  funny  \\\n",
              "0  djujEmxqpY5bmEJ3YaXiBg  jBzITjfkC7M99oN6a5HErQ     4.0     0.0    0.0   \n",
              "1  x3LyEt-uiBFCUw65oc0y5g  R9AkporqiO758oEz_g9kxQ     3.0     0.0    0.0   \n",
              "2  zZcbhKIqxcgjWO8LJUJUaQ  -Z97B_kIy1-w3nifW1PQZg     5.0     0.0    0.0   \n",
              "3  ZoN7GbeNGFyPwwKdMEr_Mw  9m9mkjkyo4HGFUWgugewHA     5.0     0.0    0.0   \n",
              "4  NlQl6Z5UOFmAgSiMo0CbHA  KE2en6iTCiCtqVS9hq50sg     5.0     0.0    0.0   \n",
              "\n",
              "   cool                                               text  \\\n",
              "0   0.0  We'd been playing a festival in Western Indian...   \n",
              "1   0.0  The experience happened on Tuesday, July 3rd, ...   \n",
              "2   0.0  Phe-nom-nom-nom-enal! Took my wife here today ...   \n",
              "3   0.0  Carne Asada tacos were good, hubby had chicken...   \n",
              "4   0.0  Delicious food.  Very generous portions.  Very...   \n",
              "\n",
              "                  date  \n",
              "0  2017-09-18 17:29:03  \n",
              "1  2018-07-04 01:02:30  \n",
              "2  2016-10-13 02:00:28  \n",
              "3  2016-07-12 15:05:25  \n",
              "4  2018-07-03 23:28:02  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>name</th>\n",
              "      <th>address</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>postal_code</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>stars_x</th>\n",
              "      <th>review_count</th>\n",
              "      <th>...</th>\n",
              "      <th>attributes</th>\n",
              "      <th>categories</th>\n",
              "      <th>review_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>stars_y</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>cool</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2AwhlMOMsYXJvskZKKG2GA</td>\n",
              "      <td>Tequila Sunrise</td>\n",
              "      <td>1551 N Green St</td>\n",
              "      <td>Brownsburg</td>\n",
              "      <td>IN</td>\n",
              "      <td>46112</td>\n",
              "      <td>39.867338</td>\n",
              "      <td>-86.390529</td>\n",
              "      <td>3.5</td>\n",
              "      <td>112.0</td>\n",
              "      <td>...</td>\n",
              "      <td>{'NoiseLevel': \"u'average'\", 'BusinessParking'...</td>\n",
              "      <td>Restaurants, Mexican</td>\n",
              "      <td>djujEmxqpY5bmEJ3YaXiBg</td>\n",
              "      <td>jBzITjfkC7M99oN6a5HErQ</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>We'd been playing a festival in Western Indian...</td>\n",
              "      <td>2017-09-18 17:29:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2AwhlMOMsYXJvskZKKG2GA</td>\n",
              "      <td>Tequila Sunrise</td>\n",
              "      <td>1551 N Green St</td>\n",
              "      <td>Brownsburg</td>\n",
              "      <td>IN</td>\n",
              "      <td>46112</td>\n",
              "      <td>39.867338</td>\n",
              "      <td>-86.390529</td>\n",
              "      <td>3.5</td>\n",
              "      <td>112.0</td>\n",
              "      <td>...</td>\n",
              "      <td>{'NoiseLevel': \"u'average'\", 'BusinessParking'...</td>\n",
              "      <td>Restaurants, Mexican</td>\n",
              "      <td>x3LyEt-uiBFCUw65oc0y5g</td>\n",
              "      <td>R9AkporqiO758oEz_g9kxQ</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>The experience happened on Tuesday, July 3rd, ...</td>\n",
              "      <td>2018-07-04 01:02:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2AwhlMOMsYXJvskZKKG2GA</td>\n",
              "      <td>Tequila Sunrise</td>\n",
              "      <td>1551 N Green St</td>\n",
              "      <td>Brownsburg</td>\n",
              "      <td>IN</td>\n",
              "      <td>46112</td>\n",
              "      <td>39.867338</td>\n",
              "      <td>-86.390529</td>\n",
              "      <td>3.5</td>\n",
              "      <td>112.0</td>\n",
              "      <td>...</td>\n",
              "      <td>{'NoiseLevel': \"u'average'\", 'BusinessParking'...</td>\n",
              "      <td>Restaurants, Mexican</td>\n",
              "      <td>zZcbhKIqxcgjWO8LJUJUaQ</td>\n",
              "      <td>-Z97B_kIy1-w3nifW1PQZg</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Phe-nom-nom-nom-enal! Took my wife here today ...</td>\n",
              "      <td>2016-10-13 02:00:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2AwhlMOMsYXJvskZKKG2GA</td>\n",
              "      <td>Tequila Sunrise</td>\n",
              "      <td>1551 N Green St</td>\n",
              "      <td>Brownsburg</td>\n",
              "      <td>IN</td>\n",
              "      <td>46112</td>\n",
              "      <td>39.867338</td>\n",
              "      <td>-86.390529</td>\n",
              "      <td>3.5</td>\n",
              "      <td>112.0</td>\n",
              "      <td>...</td>\n",
              "      <td>{'NoiseLevel': \"u'average'\", 'BusinessParking'...</td>\n",
              "      <td>Restaurants, Mexican</td>\n",
              "      <td>ZoN7GbeNGFyPwwKdMEr_Mw</td>\n",
              "      <td>9m9mkjkyo4HGFUWgugewHA</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Carne Asada tacos were good, hubby had chicken...</td>\n",
              "      <td>2016-07-12 15:05:25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2AwhlMOMsYXJvskZKKG2GA</td>\n",
              "      <td>Tequila Sunrise</td>\n",
              "      <td>1551 N Green St</td>\n",
              "      <td>Brownsburg</td>\n",
              "      <td>IN</td>\n",
              "      <td>46112</td>\n",
              "      <td>39.867338</td>\n",
              "      <td>-86.390529</td>\n",
              "      <td>3.5</td>\n",
              "      <td>112.0</td>\n",
              "      <td>...</td>\n",
              "      <td>{'NoiseLevel': \"u'average'\", 'BusinessParking'...</td>\n",
              "      <td>Restaurants, Mexican</td>\n",
              "      <td>NlQl6Z5UOFmAgSiMo0CbHA</td>\n",
              "      <td>KE2en6iTCiCtqVS9hq50sg</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Delicious food.  Very generous portions.  Very...</td>\n",
              "      <td>2018-07-03 23:28:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path = r'Desktop/ipynb notebooks - practice, examples, and class files/DATA606Capstone/yelp_academic_dataset_review.parquet'\n",
        "# # reading in converted parquet as df\n",
        "# yelp_review = pd.read_parquet(path)\n",
        "# yelp_review.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "JmxY3lFybWxi",
        "outputId": "b02889da-8bb6-4833-b644-699532a8c7a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                review_id                 user_id             business_id  \\\n",
              "0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
              "1  BiTunyQ73aT9WBnpR9DZGw  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ   \n",
              "2  saUsX_uimxRlCVr67Z4Jig  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A   \n",
              "3  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   \n",
              "4  Sx8TMOWLNuJBWer-0pcmoA  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ   \n",
              "\n",
              "   stars  useful  funny  cool  \\\n",
              "0      3       0      0     0   \n",
              "1      5       1      0     1   \n",
              "2      3       0      0     0   \n",
              "3      5       1      0     1   \n",
              "4      4       1      0     1   \n",
              "\n",
              "                                                text                date  \n",
              "0  If you decide to eat here, just be aware it is... 2018-07-07 22:09:11  \n",
              "1  I've taken a lot of spin classes over the year... 2012-01-03 15:28:18  \n",
              "2  Family diner. Had the buffet. Eclectic assortm... 2014-02-05 20:30:30  \n",
              "3  Wow!  Yummy, different,  delicious.   Our favo... 2015-01-04 00:01:03  \n",
              "4  Cute interior and owner (?) gave us tour of up... 2017-01-14 20:54:15  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>cool</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
              "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
              "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>If you decide to eat here, just be aware it is...</td>\n",
              "      <td>2018-07-07 22:09:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BiTunyQ73aT9WBnpR9DZGw</td>\n",
              "      <td>OyoGAe7OKpv6SyGZT5g77Q</td>\n",
              "      <td>7ATYjTIgM3jUlt4UM3IypQ</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>I've taken a lot of spin classes over the year...</td>\n",
              "      <td>2012-01-03 15:28:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>saUsX_uimxRlCVr67Z4Jig</td>\n",
              "      <td>8g_iMtfSiwikVnbP2etR0A</td>\n",
              "      <td>YjUWPpI6HXG530lwP-fb2A</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Family diner. Had the buffet. Eclectic assortm...</td>\n",
              "      <td>2014-02-05 20:30:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
              "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
              "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
              "      <td>2015-01-04 00:01:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sx8TMOWLNuJBWer-0pcmoA</td>\n",
              "      <td>bcjbaE6dDog4jkNY91ncLQ</td>\n",
              "      <td>e4Vwtrqf-wpJfwesgvdgxQ</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Cute interior and owner (?) gave us tour of up...</td>\n",
              "      <td>2017-01-14 20:54:15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(set(yelp['state']))\n",
        "\n",
        "# drop 'states' outside US\n",
        "yelp = yelp[-yelp['state'].isin(['AB', 'VI', 'XMS'])]\n",
        "yelp = yelp[-yelp['state'].isnull()]\n",
        "print(set(yelp['state']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWTdAy9ggrCu",
        "outputId": "04f6c0de-ba89-4267-a04b-4f7e7aa3c5a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{nan, 'FL', 'AZ', 'TN', 'MO', 'PA', 'CA', 'NV', 'DE', 'LA', 'ID', 'IN', 'NJ', 'IL'}\n",
            "{'FL', 'AZ', 'TN', 'MO', 'PA', 'CA', 'NV', 'DE', 'LA', 'ID', 'IN', 'NJ', 'IL'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "id": "4JwG849uaDO_",
        "outputId": "be506ec4-2a79-4306-839f-d3e707890f0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              business_id             name          address        city state  \\\n",
              "0  2AwhlMOMsYXJvskZKKG2GA  Tequila Sunrise  1551 N Green St  Brownsburg    IN   \n",
              "1  2AwhlMOMsYXJvskZKKG2GA  Tequila Sunrise  1551 N Green St  Brownsburg    IN   \n",
              "2  2AwhlMOMsYXJvskZKKG2GA  Tequila Sunrise  1551 N Green St  Brownsburg    IN   \n",
              "3  2AwhlMOMsYXJvskZKKG2GA  Tequila Sunrise  1551 N Green St  Brownsburg    IN   \n",
              "4  2AwhlMOMsYXJvskZKKG2GA  Tequila Sunrise  1551 N Green St  Brownsburg    IN   \n",
              "\n",
              "  postal_code   latitude  longitude  stars_x  review_count  ...  \\\n",
              "0       46112  39.867338 -86.390529      3.5         112.0  ...   \n",
              "1       46112  39.867338 -86.390529      3.5         112.0  ...   \n",
              "2       46112  39.867338 -86.390529      3.5         112.0  ...   \n",
              "3       46112  39.867338 -86.390529      3.5         112.0  ...   \n",
              "4       46112  39.867338 -86.390529      3.5         112.0  ...   \n",
              "\n",
              "             categories               review_id                 user_id  \\\n",
              "0  Restaurants, Mexican  djujEmxqpY5bmEJ3YaXiBg  jBzITjfkC7M99oN6a5HErQ   \n",
              "1  Restaurants, Mexican  x3LyEt-uiBFCUw65oc0y5g  R9AkporqiO758oEz_g9kxQ   \n",
              "2  Restaurants, Mexican  zZcbhKIqxcgjWO8LJUJUaQ  -Z97B_kIy1-w3nifW1PQZg   \n",
              "3  Restaurants, Mexican  ZoN7GbeNGFyPwwKdMEr_Mw  9m9mkjkyo4HGFUWgugewHA   \n",
              "4  Restaurants, Mexican  NlQl6Z5UOFmAgSiMo0CbHA  KE2en6iTCiCtqVS9hq50sg   \n",
              "\n",
              "  stars_y useful  funny  cool  \\\n",
              "0     4.0    0.0    0.0   0.0   \n",
              "1     3.0    0.0    0.0   0.0   \n",
              "2     5.0    0.0    0.0   0.0   \n",
              "3     5.0    0.0    0.0   0.0   \n",
              "4     5.0    0.0    0.0   0.0   \n",
              "\n",
              "                                                text                 date  \\\n",
              "0  We'd been playing a festival in Western Indian...  2017-09-18 17:29:03   \n",
              "1  The experience happened on Tuesday, July 3rd, ...  2018-07-04 01:02:30   \n",
              "2  Phe-nom-nom-nom-enal! Took my wife here today ...  2016-10-13 02:00:28   \n",
              "3  Carne Asada tacos were good, hubby had chicken...  2016-07-12 15:05:25   \n",
              "4  Delicious food.  Very generous portions.  Very...  2018-07-03 23:28:02   \n",
              "\n",
              "  sentiment  \n",
              "0   Neutral  \n",
              "1   Neutral  \n",
              "2  Positive  \n",
              "3  Positive  \n",
              "4  Positive  \n",
              "\n",
              "[5 rows x 22 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>name</th>\n",
              "      <th>address</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>postal_code</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>stars_x</th>\n",
              "      <th>review_count</th>\n",
              "      <th>...</th>\n",
              "      <th>categories</th>\n",
              "      <th>review_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>stars_y</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>cool</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2AwhlMOMsYXJvskZKKG2GA</td>\n",
              "      <td>Tequila Sunrise</td>\n",
              "      <td>1551 N Green St</td>\n",
              "      <td>Brownsburg</td>\n",
              "      <td>IN</td>\n",
              "      <td>46112</td>\n",
              "      <td>39.867338</td>\n",
              "      <td>-86.390529</td>\n",
              "      <td>3.5</td>\n",
              "      <td>112.0</td>\n",
              "      <td>...</td>\n",
              "      <td>Restaurants, Mexican</td>\n",
              "      <td>djujEmxqpY5bmEJ3YaXiBg</td>\n",
              "      <td>jBzITjfkC7M99oN6a5HErQ</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>We'd been playing a festival in Western Indian...</td>\n",
              "      <td>2017-09-18 17:29:03</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2AwhlMOMsYXJvskZKKG2GA</td>\n",
              "      <td>Tequila Sunrise</td>\n",
              "      <td>1551 N Green St</td>\n",
              "      <td>Brownsburg</td>\n",
              "      <td>IN</td>\n",
              "      <td>46112</td>\n",
              "      <td>39.867338</td>\n",
              "      <td>-86.390529</td>\n",
              "      <td>3.5</td>\n",
              "      <td>112.0</td>\n",
              "      <td>...</td>\n",
              "      <td>Restaurants, Mexican</td>\n",
              "      <td>x3LyEt-uiBFCUw65oc0y5g</td>\n",
              "      <td>R9AkporqiO758oEz_g9kxQ</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>The experience happened on Tuesday, July 3rd, ...</td>\n",
              "      <td>2018-07-04 01:02:30</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2AwhlMOMsYXJvskZKKG2GA</td>\n",
              "      <td>Tequila Sunrise</td>\n",
              "      <td>1551 N Green St</td>\n",
              "      <td>Brownsburg</td>\n",
              "      <td>IN</td>\n",
              "      <td>46112</td>\n",
              "      <td>39.867338</td>\n",
              "      <td>-86.390529</td>\n",
              "      <td>3.5</td>\n",
              "      <td>112.0</td>\n",
              "      <td>...</td>\n",
              "      <td>Restaurants, Mexican</td>\n",
              "      <td>zZcbhKIqxcgjWO8LJUJUaQ</td>\n",
              "      <td>-Z97B_kIy1-w3nifW1PQZg</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Phe-nom-nom-nom-enal! Took my wife here today ...</td>\n",
              "      <td>2016-10-13 02:00:28</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2AwhlMOMsYXJvskZKKG2GA</td>\n",
              "      <td>Tequila Sunrise</td>\n",
              "      <td>1551 N Green St</td>\n",
              "      <td>Brownsburg</td>\n",
              "      <td>IN</td>\n",
              "      <td>46112</td>\n",
              "      <td>39.867338</td>\n",
              "      <td>-86.390529</td>\n",
              "      <td>3.5</td>\n",
              "      <td>112.0</td>\n",
              "      <td>...</td>\n",
              "      <td>Restaurants, Mexican</td>\n",
              "      <td>ZoN7GbeNGFyPwwKdMEr_Mw</td>\n",
              "      <td>9m9mkjkyo4HGFUWgugewHA</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Carne Asada tacos were good, hubby had chicken...</td>\n",
              "      <td>2016-07-12 15:05:25</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2AwhlMOMsYXJvskZKKG2GA</td>\n",
              "      <td>Tequila Sunrise</td>\n",
              "      <td>1551 N Green St</td>\n",
              "      <td>Brownsburg</td>\n",
              "      <td>IN</td>\n",
              "      <td>46112</td>\n",
              "      <td>39.867338</td>\n",
              "      <td>-86.390529</td>\n",
              "      <td>3.5</td>\n",
              "      <td>112.0</td>\n",
              "      <td>...</td>\n",
              "      <td>Restaurants, Mexican</td>\n",
              "      <td>NlQl6Z5UOFmAgSiMo0CbHA</td>\n",
              "      <td>KE2en6iTCiCtqVS9hq50sg</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Delicious food.  Very generous portions.  Very...</td>\n",
              "      <td>2018-07-03 23:28:02</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# create a mapping of star ratings to sentiment categories\n",
        "sentiment_map = {1: 'Negative', 2: 'Neutral', 3: 'Neutral', 4: 'Neutral', 5: 'Positive'}\n",
        "\n",
        "# apply the mapping to the 'stars' column of the dataframe\n",
        "yelp['sentiment'] = yelp_review['stars_y'].map(sentiment_map)\n",
        "\n",
        "# print the resulting dataframe\n",
        "yelp.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yelp_review.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HRwZIhec8Pf",
        "outputId": "d93bac94-961d-45ed-ed45-f88996187de6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['business_id', 'name', 'address', 'city', 'state', 'postal_code',\n",
              "       'latitude', 'longitude', 'stars_x', 'review_count', 'is_open',\n",
              "       'attributes', 'categories', 'review_id', 'user_id', 'stars_y', 'useful',\n",
              "       'funny', 'cool', 'text', 'date', 'sentiment'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download the required NLTK resources\n",
        "nltk.download('vader_lexicon')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QkPlF0tdMWX",
        "outputId": "449856ca-37bf-4a23-a3f6-aec9fda08552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     C:\\Users\\}{\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "yelp['text_truncated'] = yelp['text'].apply(lambda seq: seq[:512])\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "print(torch.cuda.device_count())\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nz_JvBrykHQI",
        "outputId": "003a7888-e007-4c00-c2aa-64ef45135d0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yelp['text_truncated']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNwr7ySakm4H",
        "outputId": "83c49208-9f2b-42f1-d5d9-b4288ac9390e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          We'd been playing a festival in Western Indian...\n",
              "1          The experience happened on Tuesday, July 3rd, ...\n",
              "2          Phe-nom-nom-nom-enal! Took my wife here today ...\n",
              "3          Carne Asada tacos were good, hubby had chicken...\n",
              "4          Delicious food.  Very generous portions.  Very...\n",
              "                                 ...                        \n",
              "3584005    This is my favorite food truck! I only wish I ...\n",
              "3584006    This food truck was stupid. Stupidly delicious...\n",
              "3584007    Bubba never disappoints i go to his fb page an...\n",
              "3584008    The truck was invited to our office for a part...\n",
              "3584009    Plum Pit came and did my niece's graduation pa...\n",
              "Name: text_truncated, Length: 3531254, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "get_sentiment = pipeline('sentiment-analysis')\n",
        "yelp['transformers_scores'] = yelp['text_truncated'].apply(lambda x: get_sentiment(x))\n"
      ],
      "metadata": {
        "id": "W3Jngg5soalp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13c6c580-4df4-4474-9e52-b6faaa816275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKvG0RKl76eA",
        "outputId": "db1cb6c9-672d-4854-9bcf-a7e7f8b87b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
            "\n",
            "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def polarity_scores_roberta(example):\n",
        "    encoded_text = tokenizer(example, return_tensors='pt')\n",
        "    output = model(**encoded_text)\n",
        "    scores = output[0][0].detach().numpy()\n",
        "    scores = softmax(scores)\n",
        "    scores_dict = {\n",
        "        'roberta_neg' : scores[0],\n",
        "        'roberta_neu' : scores[1],\n",
        "        'roberta_pos' : scores[2]\n",
        "    }\n",
        "    return scores_dict"
      ],
      "metadata": {
        "id": "QHrrBP9g7nBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = {}\n",
        "for i, row in tqdm(yelp_review.iterrows(), total=len(yelp_review)):\n",
        "    # try:\n",
        "      text = row['text']\n",
        "      myid = row['review_id']\n",
        "      vader_result = sia.polarity_scores(text)\n",
        "      vader_result_rename = {}\n",
        "      for key, value in vader_result.items():\n",
        "          vader_result_rename[f\"vader_{key}\"] = value\n",
        "      roberta_result = polarity_scores_roberta(text)\n",
        "      both = {**vader_result_rename, **roberta_result}\n",
        "      res[myid] = both\n",
        "    # except RuntimeError:\n",
        "    #     print(f'Broke for id {myid}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a955b2d813644a69978b77c18931d39f",
            "d492394645c6426a8dc6b0d0a82aa40b",
            "63a73e496d0844c6adf51ee21ed3931b",
            "236f5bd0c040407390beae7ba7bc8238",
            "7ab1c3f31f7a4a258cfb4470b56b83b9",
            "ff139686554340bda7d1857cb7c629a2",
            "ac06e5cdc31841b78ff32de2989ff3a2",
            "50996f15f627471c85fae355216ec306",
            "3d8812a43f5e47d6be853415070a4c04",
            "297011ffef2947a2a273ec3d80465980",
            "2255fed6210743489c711b56c22013cb"
          ]
        },
        "id": "4wm4Jvoo7oAE",
        "outputId": "6beea11e-678f-4906-dbbc-08203674d256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/6990280 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a955b2d813644a69978b77c18931d39f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [51], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m vader_result\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      9\u001b[0m     vader_result_rename[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvader_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m---> 10\u001b[0m roberta_result \u001b[38;5;241m=\u001b[39m \u001b[43mpolarity_scores_roberta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m both \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mvader_result_rename, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mroberta_result}\n\u001b[0;32m     12\u001b[0m res[myid] \u001b[38;5;241m=\u001b[39m both\n",
            "Cell \u001b[1;32mIn [44], line 2\u001b[0m, in \u001b[0;36mpolarity_scores_roberta\u001b[1;34m(example)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpolarity_scores_roberta\u001b[39m(example):\n\u001b[1;32m----> 2\u001b[0m     encoded_text \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoded_text)\n\u001b[0;32m      4\u001b[0m     scores \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\tokenization_utils_base.py:2523\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2521\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[0;32m   2522\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[1;32m-> 2523\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_one(text\u001b[38;5;241m=\u001b[39mtext, text_pair\u001b[38;5;241m=\u001b[39mtext_pair, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mall_kwargs)\n\u001b[0;32m   2524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2525\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\tokenization_utils_base.py:2629\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2609\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[0;32m   2610\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[0;32m   2611\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2626\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2627\u001b[0m     )\n\u001b[0;32m   2628\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[0;32m   2630\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m   2631\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   2632\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   2633\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   2634\u001b[0m         truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   2635\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   2636\u001b[0m         stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[0;32m   2637\u001b[0m         is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[0;32m   2638\u001b[0m         pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   2639\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m   2640\u001b[0m         return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   2641\u001b[0m         return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   2642\u001b[0m         return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   2643\u001b[0m         return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   2644\u001b[0m         return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   2645\u001b[0m         return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m   2646\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   2647\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2648\u001b[0m     )\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\tokenization_utils_base.py:2702\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2692\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m   2693\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   2694\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   2695\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2699\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2700\u001b[0m )\n\u001b[1;32m-> 2702\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_plus(\n\u001b[0;32m   2703\u001b[0m     text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m   2704\u001b[0m     text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   2705\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   2706\u001b[0m     padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[0;32m   2707\u001b[0m     truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   2708\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   2709\u001b[0m     stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[0;32m   2710\u001b[0m     is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[0;32m   2711\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   2712\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m   2713\u001b[0m     return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   2714\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   2715\u001b[0m     return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   2716\u001b[0m     return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   2717\u001b[0m     return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   2718\u001b[0m     return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m   2719\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   2720\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2721\u001b[0m )\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\roberta\\tokenization_roberta_fast.py:273\u001b[0m, in \u001b[0;36mRobertaTokenizerFast._encode_plus\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    266\u001b[0m is_split_into_words \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_split_into_words\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_split_into_words, (\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    271\u001b[0m )\n\u001b[1;32m--> 273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_encode_plus(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\tokenization_utils_fast.py:502\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode_plus\u001b[39m(\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    481\u001b[0m     text: Union[TextInput, PreTokenizedInput],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    499\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchEncoding:\n\u001b[0;32m    501\u001b[0m     batched_input \u001b[38;5;241m=\u001b[39m [(text, text_pair)] \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;28;01melse\u001b[39;00m [text]\n\u001b[1;32m--> 502\u001b[0m     batched_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_encode_plus(\n\u001b[0;32m    503\u001b[0m         batched_input,\n\u001b[0;32m    504\u001b[0m         is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[0;32m    505\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m    506\u001b[0m         padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[0;32m    507\u001b[0m         truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[0;32m    508\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m    509\u001b[0m         stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[0;32m    510\u001b[0m         pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m    511\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m    512\u001b[0m         return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m    513\u001b[0m         return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m    514\u001b[0m         return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m    515\u001b[0m         return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m    516\u001b[0m         return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m    517\u001b[0m         return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m    518\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    519\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;66;03m# Return tensor is None, then we can remove the leading batch axis\u001b[39;00m\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;66;03m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001b[39;00m\n\u001b[0;32m    524\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_tensors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_overflowing_tokens:\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\roberta\\tokenization_roberta_fast.py:263\u001b[0m, in \u001b[0;36mRobertaTokenizerFast._batch_encode_plus\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m is_split_into_words \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_split_into_words\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_split_into_words, (\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    261\u001b[0m )\n\u001b[1;32m--> 263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_batch_encode_plus(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\tokenization_utils_fast.py:477\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_ids \u001b[38;5;129;01min\u001b[39;00m sanitized_tokens[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eventual_warn_about_too_long_sequence(input_ids, max_length, verbose)\n\u001b[1;32m--> 477\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatchEncoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msanitized_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitized_encodings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\tokenization_utils_base.py:210\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[1;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[0;32m    206\u001b[0m     n_sequences \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_sequences\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_sequences \u001b[38;5;241m=\u001b[39m n_sequences\n\u001b[1;32m--> 210\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\tokenization_utils_base.py:694\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[1;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tensor_type \u001b[38;5;241m==\u001b[39m TensorType\u001b[38;5;241m.\u001b[39mPYTORCH:\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available():\n\u001b[1;32m--> 694\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to convert output to PyTorch tensors format, PyTorch is not installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    695\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m    697\u001b[0m     as_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor\n",
            "\u001b[1;31mImportError\u001b[0m: Unable to convert output to PyTorch tensors format, PyTorch is not installed."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def polarity_scores_roberta(example):\n",
        "    encoded_text = tokenizer(example, return_tensors='pt')\n",
        "    output = model(**encoded_text)\n",
        "    scores = output[0][0].detach().numpy()\n",
        "    scores = softmax(scores)\n",
        "    scores_dict = {\n",
        "        'roberta_neg' : scores[0],\n",
        "        'roberta_neu' : scores[1],\n",
        "        'roberta_pos' : scores[2]\n",
        "    }\n",
        "    return scores_dict"
      ],
      "metadata": {
        "id": "YAZoqW4H65N8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# perform sentiment analysis on the reviews using the NLTK SentimentIntensityAnalyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "yelp_review['sia_scores'] = yelp_review['text'].apply(lambda x: sia.polarity_scores(x))\n",
        "\n",
        "# extract the compound scores from the sentiment analysis results\n",
        "yelp_review['compound'] = yelp_review['sia_scores'].apply(lambda x: x['compound'])\n",
        "\n",
        "# create a new column with the predicted sentiment based on the compound score\n",
        "yelp_review['predicted_sentiment'] = yelp_review['compound'].apply(lambda x: 'Positive' if x > 0 else 'Negative')\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N0z2W6RkeQZL",
        "outputId": "d3204af3-1cef-4071-8d60-539c333d02d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# perform sentiment analysis on the reviews using the NLTK SentimentIntensityAnalyzer\u001b[39;00m\n\u001b[0;32m      2\u001b[0m sia \u001b[38;5;241m=\u001b[39m SentimentIntensityAnalyzer()\n\u001b[1;32m----> 3\u001b[0m yelp_review[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msia_scores\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43myelp_review\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msia\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolarity_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# extract the compound scores from the sentiment analysis results\u001b[39;00m\n\u001b[0;32m      6\u001b[0m yelp_review[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompound\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m yelp_review[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msia_scores\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompound\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1154\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1155\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1156\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1163\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\_libs\\lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
            "Cell \u001b[1;32mIn [20], line 3\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# perform sentiment analysis on the reviews using the NLTK SentimentIntensityAnalyzer\u001b[39;00m\n\u001b[0;32m      2\u001b[0m sia \u001b[38;5;241m=\u001b[39m SentimentIntensityAnalyzer()\n\u001b[1;32m----> 3\u001b[0m yelp_review[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msia_scores\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m yelp_review[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43msia\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolarity_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# extract the compound scores from the sentiment analysis results\u001b[39;00m\n\u001b[0;32m      6\u001b[0m yelp_review[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompound\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m yelp_review[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msia_scores\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompound\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\nltk\\sentiment\\vader.py:361\u001b[0m, in \u001b[0;36mSentimentIntensityAnalyzer.polarity_scores\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;124;03mReturn a float for sentiment strength based on the input text.\u001b[39;00m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;124;03mPositive values are positive valence, negative value are negative\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;124;03mvalence.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;66;03m# text, words_and_emoticons, is_cap_diff = self.preprocess(text)\u001b[39;00m\n\u001b[1;32m--> 361\u001b[0m sentitext \u001b[38;5;241m=\u001b[39m \u001b[43mSentiText\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPUNC_LIST\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREGEX_REMOVE_PUNCTUATION\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m sentiments \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    365\u001b[0m words_and_emoticons \u001b[38;5;241m=\u001b[39m sentitext\u001b[38;5;241m.\u001b[39mwords_and_emoticons\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\nltk\\sentiment\\vader.py:274\u001b[0m, in \u001b[0;36mSentiText.__init__\u001b[1;34m(self, text, punc_list, regex_remove_punctuation)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPUNC_LIST \u001b[38;5;241m=\u001b[39m punc_list\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREGEX_REMOVE_PUNCTUATION \u001b[38;5;241m=\u001b[39m regex_remove_punctuation\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwords_and_emoticons \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_words_and_emoticons\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;66;03m# doesn't separate words from\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;66;03m# adjacent punctuation (keeps emoticons & contractions)\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_cap_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallcap_differential(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwords_and_emoticons)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\nltk\\sentiment\\vader.py:306\u001b[0m, in \u001b[0;36mSentiText._words_and_emoticons\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;124;03mRemoves leading and trailing puncutation\u001b[39;00m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;124;03mLeaves contractions and most emoticons\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;124;03m    Does not preserve punc-plus-letter emoticons (e.g. :D)\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    305\u001b[0m wes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m--> 306\u001b[0m words_punc_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_words_plus_punc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    307\u001b[0m wes \u001b[38;5;241m=\u001b[39m [we \u001b[38;5;28;01mfor\u001b[39;00m we \u001b[38;5;129;01min\u001b[39;00m wes \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(we) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, we \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(wes):\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(yelp['text'], yelp['sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "# convert the text data into a numerical format using CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vect = vectorizer.fit_transform(X_train)\n",
        "X_test_vect = vectorizer.transform(X_test)\n",
        "\n",
        "# train a Naive Bayes classifier on the training data\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train_vect, y_train)\n",
        "\n",
        "# predict the sentiment of the test data using the trained classifier\n",
        "y_pred = clf.predict(X_test_vect)\n",
        "\n",
        "# calculate the accuracy of the predictions\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy:', accuracy)"
      ],
      "metadata": {
        "id": "JCjYpevjeVc1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}